Fraude de CrÃ©dito com PySpark

Este projeto tem como objetivo realizar anÃ¡lise e tratamento de dados de
fraude de crÃ©dito utilizando PySpark, aplicando processos de leitura,
limpeza, indicadores de qualidade, cÃ¡lculos estatÃ­sticos e exportaÃ§Ã£o
dos resultados em CSV.

------------------------------------------------------------------------

ğŸš€ Funcionalidades

-   Criar sessÃ£o Spark com configuraÃ§Ãµes personalizadas.
-   Ler arquivos CSV em DataFrames Spark.
-   Limpar colunas removendo espaÃ§os extras, valores nulos, none e
    duplicados.
-   Calcular mÃ©dia de risco por regiÃ£o e salvar o resultado em CSV.
-   Gerar tabela com as Top 3 transaÃ§Ãµes mais altas.
-   Criar indicadores de qualidade com base em inconsistÃªncias nos
    dados.
-   Exportar resultados em CSV.

------------------------------------------------------------------------

ğŸ“‚ Estrutura do Projeto

    fraude_credito/
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ input/        # Arquivos CSV de entrada
    â”‚   â””â”€â”€ output/       # Resultados processados (CSV)
    â”‚
    â”œâ”€â”€ fraude_credito.py # CÃ³digo principal do projeto
    â””â”€â”€ README.md         # DocumentaÃ§Ã£o

------------------------------------------------------------------------

âš™ï¸ PrÃ©-requisitos

-   Python 3.8+
-   Apache Spark
-   Java 8 ou superior

Bibliotecas utilizadas

-   pyspark

------------------------------------------------------------------------

â–¶ï¸ Como Executar

1.  Clone este repositÃ³rio:

        git clone https://github.com/seu-usuario/fraude_credito.git
        cd fraude_credito

2.  Garanta que o Spark estÃ¡ configurado corretamente no seu ambiente.

3.  Execute o cÃ³digo:

        main.py

------------------------------------------------------------------------

ğŸ“Š Exemplos de SaÃ­da

Indicadores de Qualidade

  total_registros   total_erros   percentual_conformidade
  ----------------- ------------- -------------------------
  10000             500           95.0 %

MÃ©dia de Risco por RegiÃ£o

  location_region   media_risco
  ----------------- -------------
  Africa                0.85
  South America                0.72

Top 3 TransaÃ§Ãµes

  receiving_address   amount   timestamp
  ------------------- -------- ---------------------
  X1A2B3C             1500     2025-09-15 10:00:00
  Y4D5E6F             1200     2025-09-15 11:30:00
  Z7G8H9I             1000     2025-09-15 12:45:00

------------------------------------------------------------------------

ğŸ›  FunÃ§Ãµes Principais

-   criar_sessao_spark() â†’ Cria sessÃ£o Spark configurada.
-   ler_arquivo_csv(spark, diretorio) â†’ LÃª arquivos CSV para DataFrame.
-   limpeza_dataframe(df) â†’ Realiza limpeza e padronizaÃ§Ã£o dos dados.
-   media_risco(df, spark) â†’ Calcula mÃ©dia de risco por regiÃ£o.
-   tabela_top3_transacoes(df, spark) â†’ Gera ranking das 3 maiores
    transaÃ§Ãµes.
-   indicadores_qualidade(df, spark) â†’ Cria indicadores de qualidade do
    dataset.
-   salvar_arquivo_csv(spark, df, diretorio) â†’ Salva DataFrames em CSV.

------------------------------------------------------------------------

ğŸ“§ Contato

Caso tenha dÃºvidas ou sugestÃµes, entre em contato: - Autor: Thiago MagalhÃ£es
Tecnologia - E-mail: thiago.dmagalhaes@hotmail.com - GitHub:
github.com/thiagodmagalhaes
